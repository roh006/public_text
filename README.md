
# This is for Text Analytics for Pandas


## List of Text Preprocessing Steps
Remove HTML tags.
Remove extra whitespaces.
Convert accented characters to ASCII characters.
Expand contractions.
Remove special characters.
Lowercase all texts.
Convert number words to numeric form.
Remove numbers.


## Lowercasing
Lowercasing ALL your text data, although commonly overlooked, is one of the simplest and most effective form of text preprocessing. It is applicable to most text mining and NLP problems and can help in cases where your dataset is not very large and significantly helps with consistency of expected output.

## - Tokenization
Tokenization is a step which splits longer strings of text into smaller pieces, or tokens. Larger chunks of text can be tokenized into sentences, sentences can be tokenized into words, etc. Further processing is generally performed after a piece of text has been appropriately tokenized. Tokenization is also referred to as text segmentation or lexical analysis. Sometimes segmentation is used to refer to the breakdown of a large chunk of text into pieces larger 

## Stemming
Stemming is the process of reducing inflection in words (e.g. troubled, troubles) to their root form (e.g. trouble). The “root” in this case may not be a real root word, but just a canonical form of the original word.
![github-small](https://www.google.com/url?sa=i&url=https%3A%2F%2Ftowardsdatascience.com%2Fintroduction-to-stemming-vs-lemmatization-nlp-8c69eb43ecfe&psig=AOvVaw1hcYnZVVxhm1PEgMYrM1LA&ust=1600324360124000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCKjRkPyG7esCFQAAAAAdAAAAABAD)
